{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Продвинутый Python, семинар 8\n",
        "\n",
        "**Лектор:** Петров Тимур\n",
        "\n",
        "**Семинаристы:** Петров Тимур, Коган Александра, Романченко Полина\n",
        "\n",
        "**Spoiler Alert:** в рамках курса нельзя изучить ни одну из тем от и до досконально (к сожалению, на это требуется больше времени, чем даже 3 часа в неделю). Но мы попробуем рассказать столько, сколько возможно :)"
      ],
      "metadata": {
        "id": "5EWo4vpdHvHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Углубляемся в парсинг"
      ],
      "metadata": {
        "id": "VuWlixt0Hxn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Научились с вами парсить странички, получать товар и даже обходить блокировку роботов, которым ничего нельзя. Что же, давайте добавим динамики\n",
        "\n",
        "Если в прошлый раз мы с вами просто брали и получали результат по заданным страничкам, то теперь хотим брать страницу, из нее забирать ссылки, ходить по ним и также получать информацию о товаре. Таким образом получим реального паука"
      ],
      "metadata": {
        "id": "KnV-0Z1cH0Wt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGvu0jrRHr8_"
      },
      "outputs": [],
      "source": [
        "!pip install scrapy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сегодня в качестве нашей жертвы выберем другой маркетплейс, а именно [Алиэкспресс](https://aliexpress.ru)\n",
        "\n",
        "И сформулируем задачу так:\n",
        "\n",
        "Хотим взять все заказы по запросу \"Видеокарта\" (вот такие мы маленькие любители помайнить, видимо)"
      ],
      "metadata": {
        "id": "40R2-LA_IT8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перезходим по ссылке: https://aliexpress.ru/wholesale?SearchText=Видеокарта&g=n&page=1\n",
        "\n",
        "Ииии... тут нет никаких страниц! Есть кнопка загрузить еще и он не делает новую страницу, он просто догружает, что же делать?\n",
        "\n",
        "Ответ: внимательнее посмотреть на url-ссылку!"
      ],
      "metadata": {
        "id": "heh_WoC5I5Ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## URL-ссылки и как они работают"
      ],
      "metadata": {
        "id": "j1TXOKiYJFuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "URL (Uniform Resource Locator) - это адрес всему, что выложено в интернетах. \n",
        "\n",
        "Сам по себе URL состоит из нескольких частей:\n",
        "\n",
        "* Протокол - какой протокол должен использовать запрос. Самый частый пример: ```https//:```, но бывают и другие, например, ```mailto:```, открывающий почтовый клиент. В нашем случае все банально и просто\n",
        "\n",
        "* Domain - полное доменное имя (пример: ```example.com```), то есть к какому веб ресурсу необходимо подключиться\n",
        "\n",
        "Обратите внимание: ```vk.com``` и ```m.vk.com``` - в чем разница? В уровнях домена (m - это дополнительный уровень, который вас отсылает именно к мобильной версии сайта, а тот же com - это доменная зона)\n",
        "\n",
        "* Port - технический параметр (порт для доступа к веб-ресурсу, пример: ```:443```), обычно никто ничего не ставит, потому что он устанваливается по дефолту (80 для HTTP и 443 для HTTPS)\n",
        "\n",
        "* Parameters - параметры для передачи ресурсу. Каждый сервер их обрабатывает по-своему, в зависимости от того, как владелец это обрабатывает. Как они выглядят:\n",
        "\n",
        "```\n",
        "?key1=value1&key_2=value_2 - ? - начинаются параметры, через & идет перечисление\n",
        "```\n",
        "\n",
        "* Anchor - якорь, который вас отсылает к какой-то конкретной части (например, к какой-то плашке уже на странице etc), пример ```#anchor```\n",
        "\n",
        "* Path - может быть просто путь к файлу (```a/b/c```)"
      ],
      "metadata": {
        "id": "tKcrkJVNKG9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Имея вот такие знания, давайте обратимся к адресу:\n",
        "\n",
        "```\n",
        "https://aliexpress.ru/wholesale?SearchText=Видеокарта&g=n&page=1\n",
        "\n",
        "Параметры:\n",
        "\n",
        "SearchText=Видеокарта - наш поисковый запрос\n",
        "g = n - ???\n",
        "page = 1 - страница\n",
        "```\n",
        "\n",
        "Давайте тестировать, что за g. Посмотрели и ничего не увидели, ну ладно\n",
        "\n",
        "Но что увидели? Что изменение page показывает только нужную страницу, а не только с самого начала, ура, значит можно парсить через изменение данного параметра"
      ],
      "metadata": {
        "id": "wx-lQw3COAiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Смотрим, как перейти и как вытащить информацию"
      ],
      "metadata": {
        "id": "3znUqGGRPZ1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Открываем и видмм более красивую и приятную картинку, чем в Amazon, кто-то постарался на славу"
      ],
      "metadata": {
        "id": "tiM6uWsZPeHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1\n",
        "\n",
        "Имея страничку поиска (Aliexpress.txt) или с помощью навигации по сайту вычлените все ссылки на на карточки товаров"
      ],
      "metadata": {
        "id": "8_J622-qQsVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "s = \"\"\n",
        "with open(\"Aliexpress.txt\", 'r') as f:\n",
        "    s = f.read()\n",
        "soup = BeautifulSoup(s, 'html.parser') # указываем парсер\n",
        "print(soup.prettify()) # выглядит уже более структурно"
      ],
      "metadata": {
        "id": "onmj9SLXQ1_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 2\n",
        "\n",
        "Имея страницу (Aliexpress_item.txt) вычлените следующую информацию о товаре:\n",
        "\n",
        "* Название\n",
        "\n",
        "* Категорию\n",
        "\n",
        "* Цену\n",
        "\n",
        "* Цену без скидки (если есть скидка)\n",
        "\n",
        "* Стоимость доставки\n",
        "\n",
        "* Средний отзыв"
      ],
      "metadata": {
        "id": "RbGzgh-rSxJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "s = \"\"\n",
        "with open(\"Aliexpress_item.txt\", 'r') as f:\n",
        "    s = f.read()\n",
        "soup = BeautifulSoup(s, 'html.parser') # указываем парсер\n",
        "print(soup.prettify()) # выглядит уже более структурно"
      ],
      "metadata": {
        "id": "mK1jsmh6TRpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Название:"
      ],
      "metadata": {
        "id": "VH2O8Q9RVjb-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NIjcVTIqVQOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Категория:"
      ],
      "metadata": {
        "id": "KuiCJf4sVk7r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kvibbIrVntI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цена:"
      ],
      "metadata": {
        "id": "aNUZHfVzWIAP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "beUfrtLOWKqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цена без скидки:"
      ],
      "metadata": {
        "id": "kk05CEl0WhXm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A-81kKALWkjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стоимость доставки:"
      ],
      "metadata": {
        "id": "Sq59ASpFWwfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l156_dgdW0PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Средний отзыв (посмотрите по коду, почему ничего не получилось):"
      ],
      "metadata": {
        "id": "WTOXiiTMWyQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AbDa8Y1MW0oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 3"
      ],
      "metadata": {
        "id": "LB0szNstY_lh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведите все данные с помощью XPath"
      ],
      "metadata": {
        "id": "Di9CYTQ1ZBtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lxml import etree\n",
        "\n",
        "dom = etree.HTML(str(soup))"
      ],
      "metadata": {
        "id": "q92LUkAIZGB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tP4TLnkGZNQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отлично, мы знаем как парсить! Дело осталось за малым - подготовить нашего паука и научить его ходить по ссылкам"
      ],
      "metadata": {
        "id": "RwMKiMdTTSU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Готовим паука"
      ],
      "metadata": {
        "id": "T3FYkiZ7Tajl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На самом деле структура для такого не слишком сложная:\n",
        "\n",
        "(1) Пишем код для начала парсинга (ввести нужный запрос и пройти по нему) - первая функция\n",
        "\n",
        "(1) Пишем код для парсинга страницы поиска - вторая функция\n",
        "\n",
        "(2) Получив ссылки, пишем код для парсинга товара, который будет возвращать ответы - третья функция\n",
        "\n",
        "Ну в целом все..."
      ],
      "metadata": {
        "id": "VNwjYS25l415"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "А теперь давайте писать павука!"
      ],
      "metadata": {
        "id": "glE0renQmk_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 3"
      ],
      "metadata": {
        "id": "a9GkOBsumm-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запишите в items.py класс для товаров"
      ],
      "metadata": {
        "id": "CnrkZ4oOmtoo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 4"
      ],
      "metadata": {
        "id": "nKJjJVzamrdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запишите в pipeline.py функцию по обработке данных:\n",
        "\n",
        "(1) Все данные сохраняем в csv\n",
        "\n",
        "(2) Берем только товары с оценкой выше 4.7"
      ],
      "metadata": {
        "id": "0ZEACDJsmynN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 5"
      ],
      "metadata": {
        "id": "Va_DsHTpnAJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поправьте settings, чтобы включить pipeline"
      ],
      "metadata": {
        "id": "JVNOr6S1nJqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 6"
      ],
      "metadata": {
        "id": "KbEdhUOznYLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишите паука, который будет автоматически ходить по запросу в товары и забирать оттуда данные"
      ],
      "metadata": {
        "id": "g52TV5NwnbPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapy\n",
        "from urllib.parse import urlencode\n",
        "from urllib.parse import urljoin\n",
        "import re\n",
        "import json\n",
        "queries = ['Видеокарта']    ##Запросы (что ищем)\n",
        "API = ''                        ##API ключ для ScraperAPI\n",
        "\n",
        "def get_url(url):\n",
        "    payload = {'api_key': API, 'url': url, 'country_code': 'us'}\n",
        "    proxy_url = 'http://api.scraperapi.com/?' + urlencode(payload)\n",
        "    return proxy_url\n",
        "\n",
        "class AliexpressSpider(scrapy.Spider):\n",
        "    name = 'Aliexpress'\n",
        "\n",
        "    def start_requests(self):\n",
        "        for query in queries:\n",
        "            url = 'https://aliexpress.ru/wholesale?' + urlencode({'g': 'n', 'SearchText': query, 'page': '1'})\n",
        "            yield scrapy.Request(url=get_url(url), callback=self.parse_keyword_response)\n",
        "\n",
        "    def parse_keyword_response(self, response):\n",
        "        products = #вставить поиск ссылкок\n",
        "\n",
        "        for product in products:\n",
        "            product_url = #строим ссылку для продукта\n",
        "            yield scrapy.Request(url=get_url(product_url), callback=self.parse_product_page)\n",
        "            \n",
        "        next_page = #ссылка для следующей страницы\n",
        "        if next_page:\n",
        "            url = #делаем ссылку\n",
        "            yield scrapy.Request(url=get_url(url), callback=self.parse_keyword_response)\n",
        "\n",
        "    def parse_product_page(self, response):\n",
        "        #парсим продукт"
      ],
      "metadata": {
        "id": "CXBPYL_vbN00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Паук дня"
      ],
      "metadata": {
        "id": "uT-JIRE0ng26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.pinimg.com/originals/fc/3d/a4/fc3da4b4e143c69fab9a3877d1ea6ab4.jpg)"
      ],
      "metadata": {
        "id": "5j8TkInooEX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это паук Maratus Volans, живут они в Австралии (неядовитые) и просто очень красивые!\n",
        "\n",
        "Как известно, разноцетный окрас не особо хорош для скрытия, но хорош для другого: для привлечения самок! Поэтому они такие цветные\n",
        "\n",
        "Одни из немногих пауков, которые исполняют брачный танец, чтобы привлечь самку (но если самке не понравится, то она его съест). На картинке - поза паука при танце\n",
        "\n",
        "А также они видят сильно больше цветов, чем человек (например, ультрафиолет)"
      ],
      "metadata": {
        "id": "Z4Cm55mtoGJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.pinimg.com/originals/f7/a3/b2/f7a3b267312001a4d17a0cea530211dd.jpg)"
      ],
      "metadata": {
        "id": "A9sHIppTpGvf"
      }
    }
  ]
}